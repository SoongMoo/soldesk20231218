{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f05e75b-25bd-4183-938c-68c1cbdee72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.layers import Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "# 내가 가진 이미지를 학습시키기\n",
    "# 학습셋의 변형을 설정하는 부분\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,# 주어진 이미지의 크기를 설정\n",
    "                                  horizontal_flip = True,#수평 대칭 이미지를 50% 확률로 만듦\n",
    "                                  width_shift_range= 0.1, # 전체 크기의 15% 범위에서 좌우로 이동\n",
    "                                  height_shift_range=0.1, # 전체 크기의 15% 범위에서위,아래로 이동\n",
    "                                  #rotation_range = 5, #정해진 각도만큼 회전\n",
    "                                  shear_range=0.7, #좌표 하나를 고정시키고 나머지를 이동시킴\n",
    "                                  #zoom_range=1.2, # 확대 또는 축소\n",
    "                                  #vertical_flip=True, # 수직 대칭 이미지를 만듦 \n",
    "                                  fill_mode='nearest' # 빈 공간을 채우는 방법\n",
    "                                   # nearest : 비슷한 색으로\n",
    "                                  )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './data/train',# 학습셋이 있는 폴더의 위치\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "# 테스트셋 설정\n",
    "# 이미지 부풀리기 과정을 진행하지 않음 \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './data/test',# 학습셋이 있는 폴더의 위치\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "# CNN 모델을 만들어 적용\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff264fb-7e1d-4be1-932d-c1313acb1577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sdedu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "32/32 [==============================] - 4s 74ms/step - loss: 0.7070 - accuracy: 0.4125 - val_loss: 0.6675 - val_accuracy: 0.6400\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6870 - accuracy: 0.5688 - val_loss: 0.6778 - val_accuracy: 0.5600\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.6922 - accuracy: 0.5188 - val_loss: 0.6795 - val_accuracy: 0.7800\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6877 - accuracy: 0.5312 - val_loss: 0.6763 - val_accuracy: 0.5200\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6805 - accuracy: 0.6250 - val_loss: 0.6759 - val_accuracy: 0.4600\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6501 - accuracy: 0.6500 - val_loss: 0.6589 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.6389 - accuracy: 0.6438 - val_loss: 0.6227 - val_accuracy: 0.7200\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.6116 - accuracy: 0.7063 - val_loss: 0.5116 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.5613 - accuracy: 0.7437 - val_loss: 0.4704 - val_accuracy: 0.8200\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.4492 - accuracy: 0.8562 - val_loss: 0.3628 - val_accuracy: 0.8600\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.4636 - accuracy: 0.8125 - val_loss: 0.3165 - val_accuracy: 0.9400\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.3676 - accuracy: 0.8750 - val_loss: 0.2835 - val_accuracy: 0.9200\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.3248 - accuracy: 0.8813 - val_loss: 0.2301 - val_accuracy: 0.9200\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2767 - accuracy: 0.9125 - val_loss: 0.1890 - val_accuracy: 0.9400\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2807 - accuracy: 0.9062 - val_loss: 0.2248 - val_accuracy: 0.9400\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2353 - accuracy: 0.9312 - val_loss: 0.1744 - val_accuracy: 0.9200\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2519 - accuracy: 0.8938 - val_loss: 0.1666 - val_accuracy: 0.9800\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2241 - accuracy: 0.9312 - val_loss: 0.1781 - val_accuracy: 0.9400\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1582 - accuracy: 0.9563 - val_loss: 0.2014 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1600 - accuracy: 0.9500 - val_loss: 0.1036 - val_accuracy: 0.9600\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.1643 - accuracy: 0.9438 - val_loss: 0.1389 - val_accuracy: 0.9400\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1629 - accuracy: 0.9500 - val_loss: 0.1035 - val_accuracy: 0.9800\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1533 - accuracy: 0.9312 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1110 - accuracy: 0.9563 - val_loss: 0.1195 - val_accuracy: 0.9400\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1215 - accuracy: 0.9625 - val_loss: 0.1381 - val_accuracy: 0.9400\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.2241 - accuracy: 0.9125 - val_loss: 0.1564 - val_accuracy: 0.9400\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1363 - accuracy: 0.9625 - val_loss: 0.0747 - val_accuracy: 0.9800\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0764 - accuracy: 0.9750 - val_loss: 0.2636 - val_accuracy: 0.8600\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1429 - accuracy: 0.9438 - val_loss: 0.0794 - val_accuracy: 0.9800\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0960 - accuracy: 0.9750 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.0502 - val_accuracy: 0.9800\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0798 - accuracy: 0.9812 - val_loss: 0.0493 - val_accuracy: 0.9800\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1071 - accuracy: 0.9500 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1061 - accuracy: 0.9750 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1065 - accuracy: 0.9688 - val_loss: 0.1551 - val_accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0950 - accuracy: 0.9563 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1127 - accuracy: 0.9812 - val_loss: 0.0932 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "#모델 실행의 옵션을 설정\n",
    "model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "# 학습의 조기 중단\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# 모델 학습\n",
    "history = model.fit(train_generator, epochs=100, validation_data=test_generator, \n",
    "                  validation_steps= 10, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b402fae-9ee8-4ba4-8c74-1e102c6df85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                524352    \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15239105 (58.13 MB)\n",
      "Trainable params: 524417 (2.00 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 전이 학습\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.layers import Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, Input, models, layers,  metrics\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# 내가 가진 이미지를 학습시키기\n",
    "# 학습셋의 변형을 설정하는 부분\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,# 주어진 이미지의 크기를 설정\n",
    "                                  horizontal_flip = True,#수평 대칭 이미지를 50% 확률로 만듦\n",
    "                                  width_shift_range= 0.1, # 전체 크기의 15% 범위에서 좌우로 이동\n",
    "                                  height_shift_range=0.1, # 전체 크기의 15% 범위에서위,아래로 이동\n",
    "                                  #rotation_range = 5, #정해진 각도만큼 회전\n",
    "                                  shear_range=0.7, #좌표 하나를 고정시키고 나머지를 이동시킴\n",
    "                                  #zoom_range=1.2, # 확대 또는 축소\n",
    "                                  #vertical_flip=True, # 수직 대칭 이미지를 만듦 \n",
    "                                  fill_mode='nearest' # 빈 공간을 채우는 방법\n",
    "                                   # nearest : 비슷한 색으로\n",
    "                                  )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './data/train',# 학습셋이 있는 폴더의 위치\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "# 테스트셋 설정\n",
    "# 이미지 부풀리기 과정을 진행하지 않음 \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './data/test',# 학습셋이 있는 폴더의 위치\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "# VGG16 모델\n",
    "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "transfer_model.trainable=False\n",
    "#transfer_model.summary()\n",
    "\n",
    "# 우리의 모델을 설정\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(Flatten())\n",
    "finetune_model.add(Flatten())\n",
    "\n",
    "finetune_model.add(Dense(64))\n",
    "finetune_model.add(Activation('relu'))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Activation('relu'))\n",
    "\n",
    "finetune_model.add(Dense(1))\n",
    "finetune_model.add(Activation('sigmoid'))\n",
    "finetune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e494bd9-fc67-4d34-bbbf-e27b8b47f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 9s 242ms/step - loss: 0.6138 - accuracy: 0.6562 - val_loss: 0.5602 - val_accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 0.5313 - accuracy: 0.7375 - val_loss: 0.4014 - val_accuracy: 0.8600\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 0.4422 - accuracy: 0.7875 - val_loss: 0.4609 - val_accuracy: 0.7600\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.3736 - accuracy: 0.8313 - val_loss: 0.2836 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 0.3225 - accuracy: 0.8625 - val_loss: 0.2256 - val_accuracy: 0.9200\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 0.2744 - accuracy: 0.9062 - val_loss: 0.2993 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 0.2686 - accuracy: 0.9125 - val_loss: 0.1745 - val_accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 0.2146 - accuracy: 0.9563 - val_loss: 0.1988 - val_accuracy: 0.9800\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.2122 - accuracy: 0.9312 - val_loss: 0.2302 - val_accuracy: 0.9400\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 0.2078 - accuracy: 0.9312 - val_loss: 0.1517 - val_accuracy: 0.9800\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 0.1924 - accuracy: 0.9312 - val_loss: 0.1729 - val_accuracy: 0.9800\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.1972 - accuracy: 0.9375 - val_loss: 0.1722 - val_accuracy: 0.9400\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 0.1758 - accuracy: 0.9625 - val_loss: 0.1267 - val_accuracy: 0.9600\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 0.1404 - accuracy: 0.9500 - val_loss: 0.1785 - val_accuracy: 0.9400\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 0.2211 - accuracy: 0.9062 - val_loss: 0.3170 - val_accuracy: 0.8600\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.1257 - accuracy: 0.9812 - val_loss: 0.1832 - val_accuracy: 0.8800\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.1623 - accuracy: 0.9312 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 0.1572 - accuracy: 0.9438 - val_loss: 0.2178 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 0.1355 - accuracy: 0.9563 - val_loss: 0.1555 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 0.1239 - accuracy: 0.9625 - val_loss: 0.0958 - val_accuracy: 0.9800\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.2512 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 0.1109 - accuracy: 0.9688 - val_loss: 0.1000 - val_accuracy: 0.9800\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 0.1065 - accuracy: 0.9750 - val_loss: 0.1142 - val_accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 0.1286 - accuracy: 0.9688 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 0.1190 - accuracy: 0.9688 - val_loss: 0.1446 - val_accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "#모델 실행의 옵션을 설정\n",
    "finetune_model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "# 학습의 조기 중단\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# 모델 학습\n",
    "history = finetune_model.fit(train_generator, epochs=100, validation_data=test_generator, \n",
    "                  validation_steps= 10, callbacks=[early_stopping_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
